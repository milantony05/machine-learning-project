{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3da5645",
   "metadata": {},
   "source": [
    "# PySpark Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744fe30e",
   "metadata": {},
   "source": [
    "## 0. Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f6f12c6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "POSTGRES_JAR = \"C:/Program Files (x86)/PostgreSQL/pgJDBC/postgresql-42.7.2.jar\"\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .appName(\"Chinook_PySpark\")\n",
    "         .master(\"local[*]\")\n",
    "         .config(\"spark.jars\", POSTGRES_JAR)\n",
    "         .getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b9985b",
   "metadata": {},
   "source": [
    "## 1. Connection details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07ab7595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "JDBC URL: jdbc:postgresql://localhost:5432/chinook\n"
     ]
    }
   ],
   "source": [
    "PG_HOST = \"localhost\"\n",
    "PG_PORT = 5432\n",
    "PG_USER = \"postgres\"\n",
    "PG_PASSWORD = \"pass1234\"\n",
    "PG_DB = \"chinook\"\n",
    "\n",
    "jdbc_url = f\"jdbc:postgresql://{PG_HOST}:{PG_PORT}/{PG_DB}\"\n",
    "connection_properties = {\n",
    "    \"user\": PG_USER,\n",
    "    \"password\": PG_PASSWORD,\n",
    "    \"driver\": \"org.postgresql.Driver\"\n",
    "}\n",
    "print(\"JDBC URL:\", jdbc_url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be09217",
   "metadata": {},
   "source": [
    "## 2. Helper - load any Chinook table as a DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c2f26106",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import DataFrame\n",
    "\n",
    "def load_table(table_name: str) -> DataFrame:\n",
    "    print(f\"Loading table '{table_name}'\")\n",
    "    return (spark.read\n",
    "            .format(\"jdbc\")\n",
    "            .option(\"url\", jdbc_url)\n",
    "            .option(\"dbtable\", table_name)\n",
    "            .options(**connection_properties)\n",
    "            .load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ad6ff11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading table 'artist'\n",
      "Loading table 'album'\n",
      "Loading table 'track'\n",
      "Schema for artist:\n",
      "root\n",
      " |-- artist_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      "\n",
      "Row count: 275\n",
      "Schema for album:\n",
      "root\n",
      " |-- album_id: integer (nullable = true)\n",
      " |-- title: string (nullable = true)\n",
      " |-- artist_id: integer (nullable = true)\n",
      "\n",
      "Row count: 347\n",
      "Schema for track:\n",
      "root\n",
      " |-- track_id: integer (nullable = true)\n",
      " |-- name: string (nullable = true)\n",
      " |-- album_id: integer (nullable = true)\n",
      " |-- media_type_id: integer (nullable = true)\n",
      " |-- genre_id: integer (nullable = true)\n",
      " |-- composer: string (nullable = true)\n",
      " |-- milliseconds: integer (nullable = true)\n",
      " |-- bytes: integer (nullable = true)\n",
      " |-- unit_price: decimal(10,2) (nullable = true)\n",
      "\n",
      "Row count: 3503\n"
     ]
    }
   ],
   "source": [
    "artist_df = load_table(\"artist\")\n",
    "album_df  = load_table(\"album\")\n",
    "track_df  = load_table(\"track\")\n",
    "\n",
    "for name, df in [(\"artist\", artist_df), (\"album\", album_df), (\"track\", track_df)]:\n",
    "    print(f\"Schema for {name}:\")\n",
    "    df.printSchema()\n",
    "    print(f\"Row count: {df.count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c523dd4",
   "metadata": {},
   "source": [
    "## 3. Select & Filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d4563c70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------------------------+----------+------------+\n",
      "|track_id|name                                  |unit_price|milliseconds|\n",
      "+--------+--------------------------------------+----------+------------+\n",
      "|2819    |Battlestar Galactica: The Story So Far|1.99      |2622250     |\n",
      "|2820    |Occupation / Precipice                |1.99      |5286953     |\n",
      "|2821    |Exodus, Pt. 1                         |1.99      |2621708     |\n",
      "|2822    |Exodus, Pt. 2                         |1.99      |2618000     |\n",
      "|2823    |Collaborators                         |1.99      |2626626     |\n",
      "|2824    |Torn                                  |1.99      |2631291     |\n",
      "|2825    |A Measure of Salvation                |1.99      |2563938     |\n",
      "|2826    |Hero                                  |1.99      |2713755     |\n",
      "|2827    |Unfinished Business                   |1.99      |2622038     |\n",
      "|2828    |The Passage                           |1.99      |2623875     |\n",
      "+--------+--------------------------------------+----------+------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Tracks that cost more than 99 cents, showing a few key columns\n",
    "expensive_tracks = (track_df\n",
    "                    .select(\"track_id\", \"name\", \"unit_price\", \"milliseconds\")\n",
    "                    .filter(track_df.unit_price > 0.99))\n",
    "\n",
    "expensive_tracks.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae7d3826",
   "metadata": {},
   "source": [
    "## 4. Add a Column - `withColumn()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c2f582e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------------+--------------+\n",
      "|name                                   |length_minutes|\n",
      "+---------------------------------------+--------------+\n",
      "|For Those About To Rock (We Salute You)|5.73          |\n",
      "|Balls to the Wall                      |5.71          |\n",
      "|Fast As a Shark                        |3.84          |\n",
      "|Restless and Wild                      |4.2           |\n",
      "|Princess of the Dawn                   |6.26          |\n",
      "+---------------------------------------+--------------+\n",
      "only showing top 5 rows\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "tracks_with_minutes = track_df.withColumn(\n",
    "    \"length_minutes\",\n",
    "    F.round(track_df.milliseconds / 60000, 2)\n",
    ")\n",
    "\n",
    "tracks_with_minutes.select(\"name\", \"length_minutes\").show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14814e4e",
   "metadata": {},
   "source": [
    "## 5. GroupBy & Aggregate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82212d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-----------+\n",
      "|album_id|track_count|\n",
      "+--------+-----------+\n",
      "|     141|         57|\n",
      "|      23|         34|\n",
      "|      73|         30|\n",
      "|     229|         26|\n",
      "|     251|         25|\n",
      "|     230|         25|\n",
      "|     253|         24|\n",
      "|     231|         24|\n",
      "|      83|         24|\n",
      "|     255|         23|\n",
      "+--------+-----------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Number of tracks per album\n",
    "tracks_per_album = (track_df\n",
    "                    .groupBy(\"album_id\")\n",
    "                    .agg(F.count(\"track_id\").alias(\"track_count\"))\n",
    "                    .orderBy(F.desc(\"track_count\")))\n",
    "\n",
    "tracks_per_album.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4ada3a6",
   "metadata": {},
   "source": [
    "## 6. Joining DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dab2adf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------------------+-----------------------------------------------------------------------------------------------+\n",
      "|artist                                  |album                                                                                          |\n",
      "+----------------------------------------+-----------------------------------------------------------------------------------------------+\n",
      "|Heroes                                  |Heroes, Season 1                                                                               |\n",
      "|Antal Doráti & London Symphony Orchestra|Tchaikovsky: 1812 Festival Overture, Op.49, Capriccio Italien & Beethoven: Wellington's Victory|\n",
      "|Frank Sinatra                           |My Way: The Best Of Frank Sinatra [Disc 1]                                                     |\n",
      "|The Black Crowes                        |Live [Disc 2]                                                                                  |\n",
      "|The Black Crowes                        |Live [Disc 1]                                                                                  |\n",
      "|Fretwork                                |Armada: Music from the Courts of England and Spain                                             |\n",
      "|Spyro Gyra                              |Morning Dance                                                                                  |\n",
      "|Spyro Gyra                              |Heart of the Night                                                                             |\n",
      "|Yehudi Menuhin                          |Bartok: Violin & Viola Concertos                                                               |\n",
      "|Stevie Ray Vaughan & Double Trouble     |In Step                                                                                        |\n",
      "+----------------------------------------+-----------------------------------------------------------------------------------------------+\n",
      "only showing top 10 rows\n"
     ]
    }
   ],
   "source": [
    "# Join albums to artists to list album titles with artist names\n",
    "album_artist = (album_df\n",
    "                .join(artist_df, album_df.artist_id == artist_df.artist_id, \"inner\")\n",
    "                .select(artist_df.name.alias(\"artist\"), album_df.title.alias(\"album\")))\n",
    "\n",
    "album_artist.show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8e20081",
   "metadata": {},
   "source": [
    "## 7. Spark SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d6b5d1a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------+----------+\n",
      "|         artist|num_tracks|\n",
      "+---------------+----------+\n",
      "|    Iron Maiden|       213|\n",
      "|             U2|       135|\n",
      "|   Led Zeppelin|       114|\n",
      "|      Metallica|       112|\n",
      "|           Lost|        92|\n",
      "|    Deep Purple|        92|\n",
      "|      Pearl Jam|        67|\n",
      "|  Lenny Kravitz|        57|\n",
      "|Various Artists|        56|\n",
      "|     The Office|        53|\n",
      "+---------------+----------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Register temp views\n",
    "artist_df.createOrReplaceTempView(\"artists\")\n",
    "album_df.createOrReplaceTempView(\"albums\")\n",
    "track_df.createOrReplaceTempView(\"tracks\")\n",
    "\n",
    "# Top 10 artists by total track count\n",
    "spark.sql(\"\"\"\n",
    "    SELECT a.name AS artist, COUNT(t.track_id) AS num_tracks\n",
    "    FROM artists a\n",
    "    JOIN albums al ON a.artist_id = al.artist_id\n",
    "    JOIN tracks t  ON t.album_id = al.album_id\n",
    "    GROUP BY a.name\n",
    "    ORDER BY num_tracks DESC\n",
    "    LIMIT 10\n",
    "\"\"\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a2f0d05",
   "metadata": {},
   "source": [
    "## 8. Save Results – write locally as Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "51768adb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote sample Parquet to top_artists.parquet\n"
     ]
    }
   ],
   "source": [
    "output_path = \"top_artists.parquet\"\n",
    "\n",
    "spark.sql(\"SELECT * FROM artists LIMIT 1\").write.mode(\"overwrite\").parquet(output_path)\n",
    "print(\"Wrote sample Parquet to\", output_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77ebe327",
   "metadata": {},
   "source": [
    "---\n",
    "### Summary Table: Common PySpark Transformations\n",
    "\n",
    "| Transformation | PySpark Example |\n",
    "|----------------|----------------|\n",
    "| Select columns | `df.select(\"col1\", \"col2\")` |\n",
    "| Filter rows | `df.filter(df.col1 > 10)` |\n",
    "| Group and agg | `df.groupBy(\"col1\").agg(F.count(\"*\"))` |\n",
    "| Join DataFrames | `df1.join(df2, df1.key == df2.key)` |\n",
    "| Add column | `df.withColumn(\"new_col\", F.expr(\"col1 + col2\"))` |\n",
    "| Drop column | `df.drop(\"col_to_drop\")` |\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
